---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
# Remove comments and add values where applicable.
# The descriptions below should be self-explanatory

title: "Helping You Write Academic Papers in R using Texevier"
#subtitle: "This will appear as Right Header"

documentclass: "elsarticle"

# --------- Thesis title (Optional - set to FALSE by default).
# You can move the details below around as you please.
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Nico Katzke}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a  png logo in an img folder in your root and uncomment this. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:

# --------- Front Page
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Nico Katzke^[__Contributions:__  \\newline _The authors would like to thank no institution for money donated to this project. Thank you sincerely._]"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Prescient Securities, Cape Town, South Africa" # First Author's Affiliation
Email1: "nfkatzke\\@gmail.com" # First Author's Email address

Author2: "John Smith"
Ref2: "Some other Institution, Cape Town, South Africa"
Email2: "John\\@gmail.com"
CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.

Author3: "John Doe"
Email3: "Joe\\@gmail.com"

CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE

keywords: "Multivariate GARCH \\sep Kalman Filter \\sep Copula" # Use \\sep to separate
JELCodes: "L250 \\sep L100"

# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.

# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
# This is done by hard-setting the spacing dimensions. Set to FALSE if you want LaTeX to optimize this for your paper.

# --------- Line numbers
linenumbers: FALSE # Used when submitting to journal

# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
# Hit download, store it in Tex/ folder, and change reference below - easy.
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
#  @grinold2000
#  @Someoneelse2010

# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: "Journal of Finance"   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.

### Adding additional latex packages:
# header-includes:
#    - \usepackage{colortbl} # Add additional packages here.

output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
  Abstract to be written here. The abstract should not be too long and should provide the reader with a good understanding what you are writing about. Academic papers are not like novels where you keep the reader in suspense. To be effective in getting others to read your paper, be as open and concise about your findings here as possible. Ideally, upon reading your abstract, the reader should feel he / she must read your paper in entirety.
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')
# Note: Include = FALSE implies the code is executed, but not printed in your pdf.
# warning and message = FALSE implies ugly messages and warnings are removed from your pdf.
# These should be picked up when you execute the command chunks (code sections below) in your rmd, not printed in your paper!

# Lets load in example data, and see how this can be stored and later called from your 'data' folder.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
Example_data <- Texevier::Ex_Dat

# Notice that as you are working in a .Rproj file (I am assuming you are) - the relative paths of your directories start at your specified root.
# This means that when working in a .Rproj file, you never need to use getwd() - it is assumed as your base root automatically.
write_rds(Example_data, path = "data/Example_data.rds")

```


<!-- ############################## -->
<!-- # Start Writing here: -->
<!-- ############################## -->

# Introduction \label{Introduction}

importance of Monte Carlo methods

path dependence; first rule of investment management

Due to the aforementioned sensitivity issues surrounding errors in the expected return estimation, this work will only cover so-called risk based portfolios, since these techniques intentionally forego this input. These include the naive equal weight, inverse variance, hierarchical risk parity, equal risk contribution and the minimum variance portfolios. _The theoretical underpinnings of each will be reviewed as well as their relative performance in historical back tests_.

". Markowitz’s curse is that the more correlated investments are, the
greater is the need for a diversified portfolio—and yet
the greater are that portfolio’s estimation errors. [@lopez]"

# Aims and Objectives

This work aims to use Monte Carlo Methods to uncover the relationship between a market's covariance structure and the risk return properties of various risk based portfolio algorithms. This will be achieved through the following objectives.

1. Design and create four distinctive \emph{ad hoc} correlation matrices and build one empirical _50 by 50_ correlation matrix, each representing a market with a different risk structure. These from markets structure possessing no clusters to those exhibiting hierarchical clustering.

2. Use the R package _MCmarket_ to perform Monte Carlo Simulations, using each of the five correlation matrices from step one as the primary input [REFERENCE MYSELF]. The markets will be built to posses student t multivariate distributions, with 3 degrees of freedom. Meanwhile the individual asset returns will each be normally distributed with a random mean and standard deviation. Each market type will be simulated 10 000 times across 300 periods. 

3. Use the simulated market data to calculate the returns obtained from various risk based portfolio's. The first __100__ periods will be used estimate an out of sample covariance matrix, this will be used to calculate portfolio weights. These weights will remain for the next 50 periods after which portfolios will be rebalanced by looking back _100_ periods, recalculating the covariance matrix and the new portfolio weights. This process is repeated until all _300_ simulated periods have been considered. Therefore, each portfolio will end up with a series of _199_ returns.

4. The performance of each portfolio will then be compared and contrasted using various portfolio risk/return analytics. Portfolio optimisers will be compared with each other within market types and with themselves across markets types. 


# Litrature Review

## A Review of Portfolio Optimisation Algorithms

### Introduction

Since Harry Markovitz's (1952) seminal work on mean-variance portfolios scholars from around the globe have been aspiring to develop a robust algorithm capable of situating a portfolio on the efficient frontier _ex ante_. There are now a wide array of available alternatives portfolio optimisers raging from simple heuristic based approaches to advanced mathematical algorithms based on quadratic optimization, random matrix theory and machine learning methods; with many more are still in the making.

This literature review review will cover some common issues discussed within the literature surrounding portfolio optimization in general, the five risk-based portfolios evaluated in this work, their respective performance in empirical back tests and Monte Carlo Studies and finally the importance of using Monte Carlo methods when stress testing portfolio optimization algorithms will be discussed. 

### Common Issues Portfolio Optimizers
 
When working with in sample data Portfolio optimization tends to be a perfect science, but out of sample it becomes more of an art form where it is often preferable to work on heuristic than hard rules. This section highlights some gneral issues, highlighted within the portfolio optimization literature, that tend to worsen their out of sample performance.

Firstly, mean-variance optimisers, like those introduced by @markowitz, rely heavily on the accuracy of their expected return forecasts. Small changes in the expected return input can lead to large changes in portfolio weights [@lopez]. Since in practice expected returns are extremely difficult, if not impossible, to accurately estimate, this issue serves as a major hindrance to their wide spread use. Due to this issue the so-called risk based portfolio's that intentionally avoid using expected return forecasts have garnered a lot of attention [@maillard2010]. 

Unfortunately, these risk based portfolios are not void of issues. The quadratic programming methods used in many portfolio optimisers, including the mean variance and many risk-based, require the inversion of some positive-definite covariance matrix. This positive definiteness requirement can cause issues as covariance matrices estimated on empirical data are sometimes not positive definite, in which case their inverse does not exist and these portfolio's don't have solutions [@ref]. A common method to get around this issue is to simply transform the non-posetive definate matrix into its closest positive definite form. 

The covariance estimation step is particularly susceptible to error if the covariance matrix suffers from a high condition number. A condition number is defined as the absolute value of the ratio between a covariance matrix's largest and smallest eigenvalues [@lopez; @lopez2012]. The conditional number is smallest in diagonal matrices (they have a conditional number of 1) and it increases as more correlated variables are added. When working with high conditional number matrices a small change in a single entry's estimated covariance can greatly alter its inverse, which in turn can effect the portfolio weights [@lopez]. This is exacerbated by the fact that covariance matrices themselves are prone to estimation error [@zhou2019]. For a sample with a given number of periods, larger dimension covariance matrices are prone to more noise in estimation. This is essentially due to a reduction in degrees of freedom as a sample of at least $1/2N(N+1)$ independent and identically distributed (iid) observations are required to estimate an $N\times N$ covariance matrix [@lopez [p. 60]]. Furthermore, financial market covariance structures tend to vary over time and have been know to change rapidly during so-called regime changes [@lopez]. This exacerbates the issue of requiring a large number of observations when estimating the covariance matrix, as there is no guarantee that passed data will be a good refection of the future and looking further into the passed decreases the likelihood of it being so. 

### Risk Based Portfolio's

This section reviews the intuition and technical underpinnings within the litrature surrounding the so-called risk-based portfolios. These include the equal weight (EW), minimum variance (MV), inverse volatility (IV), equal risk contribution and the maximum diversification portfolios. The EW is a simple heuristic approach, the minimum variance is more akin to a Markovitz (1952) mean variance portfolio, while the inverse-variance (IV), equal risk contrition (ERC) and maximum diversification (MD) are quite similar in that they each assume that adequate diversification can be obtained by allocating equal risk to each investible security.

#### Naive Equal Weight (EW)

Perhaps the oldest and most simple portfolio diversification heuristic constitutes holding a weight of $1/N$ of the $N$ total assets available to the investor [@demiguel2009]. In layman's terms this can be describes as putting an equal number of eggs in each available basket. This portfolio is commonly called the equal weight or 1/N portfolio, its failure to recognize the importance of bothe the relative asset variance and the covariance between assets has also resulted in it being referred to as the naive portfolio. Its simplicity has resulted in it commonly being used as the benchmark portfolio.  

Despite its simplistic nature empirical studies tend to find a statistically insignificant difference in Sharp ratio between the naive portfolio and more advanced portfolio optimisers. This finding was made in @demiguel2009 who looked at the mean-variance, minimum-variance and Bayes-Stein portfolio's, where EW also performed surprisingly well from a total return perspective.

#### Minimum Variance (MV)

Portfolio optimisers designed to exhibit the minimum variance have more recently garnered a lot of attention, largely due their tendency to achieve surprisingly high returns in historical back tests [@clarke2011]. This performance has been attributed to the empirical phenomenon that low volatility stocks tend to earn returns in excess of the market, and high beta stocks tend not to be rewarded by higher returns [@clarke2011; @fama1992]. These findings are contrary financial economic theory. For example, the minimum variance (MV) portfolio tends to achieve cumulative returns equal to or slightly greater than market capitalization weighted portfolio's whilst maintaining consistently lower variance and achieving a noticeable improvement in downside risk mitigation, even during times of financial crisis [@clarke2011]. Interestingly, the MV portfolio is the only portfolio of the efficient frontier that does not depend on expected return forecasts[@lopez].

The minimum variance portfolio selects security weights such that the resulting portfolio correspond to that with the lowest possible in sample volatility. Therefore, it has the lowest expected volatility and is, in theory, safest/least risky portfolio [@rawl2012]. Its primary input is a variance covariance matrix, which it uses to minimize aggregate portfolio volatility. This is accomplished by overweighting low volatility and low correlation securities [@rawl2012]. This approach often works well out of sample, but if left unrestricted is known to build highly concentrated portfolio's [@lopez]. Its sole objective to minimize portfolio volatility has been cited as the primary reason for this. When near trough of its objective function it to achieves minor reductions in _ex ante_ volatility by greatly favoring a small number of low volatility/correlation securities [@lopez [p. 68]]. This tendency to produce highly concentrated portfolio's be costly out of sample as the portfolio has not sufficiently diversifies idiosyncratic risk, it puts too many eggs in a small number of baskets. In practice This issue can  be countered by applying cleaver maximum and minimum constraints on portfolio weights.

Let $\sum$ indicate the markets variance covariance matrix and $w=\{w_i,..., w_N \}$ be a vector of length N containing individual security weights. The vector containing MV portfolio weights can new be described as [@rawl2012]:

$w^*=arg\min(w'\sum w)\ \ \ s.t.\ \sum^N_iw_i=1$

#### Inverse-Varience (IV) Weighting

The IV portfolio, refered to as the equal-risk budget (ERB) portfolio in @leote, aims to allocate an equal risk budget to each investible security [@leote]. Where the risk budget is defined as the the product of a the security's weight and volatility. Therefore, if we define $\sigma_i$ as security i's volatility, then marginal volatility is equally distributed across N securities by setting security weights as such:

$w_{iv}=(\frac{1/\sigma_1}{\sum^N_{j=1} 1/\sigma}, ...,\frac{1/\sigma_N}{\sum^N_{j=1} 1/\sigma} )$

#### Equal Risk Contribution (ERC)

The ERC portfolio is similar to the IV, but also takes covariance into account [@leote]. The basic idea behind the ERC is to weight the portfolio such that each security contributes equally to risk, which in turn maximises risk diversification [@maillard2010]. Generally speaking the ERC acts similar to a weight constrained minimum variance portfolio, with constraints ensuring that adequate diversification is maintained. The weights of the ERC portfolio $x=(x_1,x_2,...,x_n)$ consisting of n assets is calculated as follows.

let $\sigma_i^2$ resemble asset i's variance, $\sigma_{ij}$ the covariance between asset i and j and $\sum$ be the markets variance covariance matrix. Portfolio risk can now be written as $sigma(x)=\sqrt{x^T\sum x}=\sum_i\sum_{j\neq i}x_ix_j\sigma_{ij}$ [@maillard2010]. The marginal risk contribution $\partial_{x_i}\sigma(x)$ can then be defined as follows [@maillard2010]:

$\partial_{x_i}\sigma(x)=\frac{\partial\sigma(x)}{\partial x_i}=\frac{x_i\sigma_i^2+\sum_{j\neq i}x_j\sigma_{ij}}{\sigma(x)}$


Therefore, $\partial_{x_i}\sigma(x)$ refers to the change in portfolio volatility resulting from a small change in asset i's weight. ERC uses this definition to guide its algorithms central objective to equate the risk contribution for each asset in the portfolio _ex ante_. If we define $(\sum x)_i$ as the $i^{th}$ row resulting from the product of $\sum$ with x and note that $\partial_{x_i}\sigma(x)=(\sum x)_i$, then the optimal ERC weight can be written as [@maillard2010]:

$x^*=\{x \ \epsilon[0,1]^n:\sum x_i=1, x_i \times (\sum x)_i=x_j \times (\sum x)_j \ \forall  \ i,j \}$



#### Maximum Diversification (MD)

@choueifaty2008 originally designed the MD portfolio to maximize a diversification ratio (DR), defined as the as the sum of each securities risk bucket divided by portfolio volatility [@leote]. If we define $w=(w_1,...w_N)^T$ as a vector of portfolio weights, V as a vector of asset volatilities and $\sum$ as the covariance matrix. Then the DR can be expresses as:

$DR= \frac{w'.V}{\sqrt{w'Vw}}$

Therefore, much like the IV and ERC portfolio's, the MD portfolio attempts to diversify the portfolio by allocating equal risk to each security [@choueifaty2008]. The MD portfolio accomplishes this by over-weighting low volatility securities and those that are less correlated with other stocks [@leote]. For detail regarding the theoretical results and properties of the MD portfolio see @choueifaty2008 [pp. 33-35].

'The MD strategy, introduced by Choueifaty and Coignard [2008], invests in the portfolio that maximizes a diversification ratio. The ratio
is the sum of the risk budget allocated to each
stock in the portfolio divided by the portfolio
volatility. This strategy should invest in stocks
that are less correlated to other stocks.' (copy pasted)

## Empirical Backtests 

@choueifaty2013 conducted an empirical back test comparing the relative performance if numerous portfolio optimisers between 1999 and 2010. They used historical data from the MSCI World world index and considered the largest 50% of assets at each semi-annual rebalance date. At each rebalance date the covariance matrices, used as inputs in the portfolio optimisers, were estimated using the passed years worth of data [@choueifaty2013]. This was done to reduce noise in estimation. All portfolio's were restricted to long only. The MV portfolio achieved an annual return of 6.7% and outperformed the ERC and EW portfolio's who returned 6.3% and 5.8% respectively. Unsurprisingly, the MV portfolio possessed the lowest daily volatility (10%) followed by the ERC and then the EW portfolio's (with 12.9% and 16.4% respectively). Accordingly the MV portfolio scored the highest sharp ratio (0.36) followed by the ERC and EW portfolio's (0.24 and 0.16 respectively). 

# Methadology

This work used Monte Carlo simulation methods to investigate the link between a markets correlation structure and the relative performance of the EW, MV, IV, ERC and MD portfolios. The note the following terminology: the term market can be thought of as a single observation consisting of the daily returns for a number of assets, while market type refers to an set of markets each designed to posses the same risk characteristics. 

The R package MCmarket was used to simulate five distinctive market types, each corresponding to a unique correlation structure [@mcmarket]. Four of the correlation matrices were designed _ad hoc_, to posses a unique correlation structure, while the fifth was calculated using emperical S&P 500 data. These correlation matrices range from one exhibiting no correlation (i.e. a diagonal matrix) to one with hierarchical clustering (see \ref{corr_struc}) . 

The long only EW, MV, IV, ERC and MD portfolios were then backtested on the simulated markets using periodic reweighting. 

Portfolio analytics were then performed for each portfolio type on each realization within the market types. These portfolio analytics include the standard deviation (sd) of daily returns, downside deviation, value at risk (VaR), conditional VAR (CVaR), Sharp ratio, average drawdown and maximum drawdown. The mean and median of the portfolio metrics are then calculated for each market type.

Finally, the portfolio metrics are compared within portfolio types across market types and within market types across portfolio types. 

## Correlation Structures \label{corr_struc}

This section describes the process and motivation behind the creation of the four _ad hoc_ correlation matrices (section \ref{adhoc}) and the empirical correlation matrix (section \ref{emp) used as the primary inputs in the Monte Carlo simulations. 


### Ad Hoc \label{adhoc}

Figure \ref{corr_mats} presents the four _ad hoc_ correlation matrices used in this study.

```{r corr mats, fig.cap="\\label{corr_mats} Correlation Matricies"}
pacman::p_load(MCmarket, tidyverse, patchwork, ggcorrplot)

corr_1 <- diag(50) %>% ggcorrplot(hc.order = TRUE, title = "Diagonal Matrix", show.legend = FALSE)
corr_2 <- gen_corr(D = 50, clusters = "none") %>% ggcorrplot(title = "No Clusters", show.legend = FALSE)
corr_3 <- gen_corr(D = 50, clusters = "non-overlapping", num_clusters = 5) %>%
  ggcorrplot(hc.order = TRUE, title = "Five Clusters", show.legend = FALSE)
corr_4 <- gen_corr(D = 50, clusters = "overlapping", 
                   num_clusters = c(10,5,2), num_layers = 3) %>% 
  ggcorrplot(hc.order = TRUE, title = "Overlapping Clusters", show.legend = FALSE)

my_title <- expression(paste(italic("ad hoc"), " Correlation Matrices"))

(corr_1 + corr_2) / (corr_3 + corr_4) + 
  patchwork::plot_annotation(title = my_title,
                             theme = theme(plot.title = element_text(hjust = 0.3, size=15))) 
  
```

### Emperical \label{emp}

The empirical correlation matrix used in this study was calculated by randomly selecting the daily returns for 50 of the largest (market capitalization) 100 S&P 500 stocks between 1 January 2016 and 1 January 2021. Markets capitalization?? were measured on 1 January 2021. The covariance matrix was then calculated using the R package fitHeavyTail. This package uses ML estimation to fit a multivariate t-distribution according to the following methodology. 

Chuanhai Liu and Donald B. Rubin, “ML estimation of the t-distribution using EM and its extensions, ECM and ECME,” Statistica Sinica (5), pp. 19-39, 1995. 


```{r}
load(file = "data/emp_corr.rda")
ggcorrplot::ggcorrplot(emp_corr, title = "Emperical Correlation Matrix", hc.order = TRUE) +
  theme(legend.position = "none",
        axis.text.y = element_text(size=7),
        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=7))
  
```


## Monte Carlo

This work uses the R package MCmarket to carry out its Monte Carlo simulations. This package uses a generalized Monte Carlo framework from @mcref. 

## Back Tests

To remain consistent with the literature, a long-only constraint was applied to all portfolio's. In addition, a constraint limiting the maximum weight for a single security to _20%_. This additional constraint is intended to prevent some portfolio's from building excessively highly concentrated holdings, while remaining flexible enough to punish those who do so. Therefore, the constraints are effectively providing a fair playing ground for the portfolio's to compete. 

The first 50 periods were used to estimate the co-variance matrix, used as the primary input in portfolio weight calculations for the respective portfolios. These weights were then used in conjunction with the simulated returns to calculate the returns for the respective portfolios. d

## Portfolio Analytics


# Results and Discussion

# Conclusion

I hope you find this template useful. Remember, stackoverflow is your friend - use it to find answers to questions. Feel free to write me a mail if you have any questions regarding the use of this package. To cite this package, simply type citation("Texevier") in Rstudio to get the citation for @Texevier (Note that united references in your bibtex file will not be included in References).

<!-- Make title of bibliography here: -->
<!-- \newpage -->

\newpage
# References {-}

<div id="refs"></div>

\newpage
# Appendix {-}

### Hierarchical Risk Parity (HRP)

Due to the multitude of robustness issues related to traditional portfolio optimisers, @lopez developed a new approach incorporating machine-learning methods and graph theory [@arevalo]. @lopez argues that the "lack of hierarchical structure in a correlation matrix allows weights to vary freely in unintended ways" and that this contributes to the instability issues. His HRP algorithm requires only a singular co-variance matrix and can utilize the information within without the need for the positive definite property [@lopez]. This procedure works in three stages:

@lopez carried out an in sample simulation study comparing the respective allocations of the long-only minimum variance, IVP and HRP portfolios using a co-variance matrix using a condition number that is "not unfavourable" to the minimum variance portfolio. The simulated data consisted of 10000 observations across 10 variables. The following findings were made: The minimum variance portfolio concentrated 92.66% of funds in the top 5 holdings and assigned a zero weight to 3 assets. _Conversly_, HRP only assigned 62.5% of its funds to the top 5 holdings [@lopez]. The minimum variance portfolio's objective function causes it to build highly concentrated portfolio's in favor of a small reduction in volatility; the HRP portfolio had only a slightly higher volatility [@lopez]. This apparent diversification advantage achieved by the minimum variance portfolio is rather deceptive as the portfolio remains highly susceptible to idiosyncratic risk incidents within its top holdings [@lopez]. This claim was further validated by the finding that HRP achieved significantly lower out of sample variance compared to the minimum variance portfolio.
## Appendix A {-}

Some appendix information here

## Appendix B {-}

